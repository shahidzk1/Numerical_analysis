{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dd4b91-7975-40b6-b5e3-d0f33522abf8",
   "metadata": {},
   "source": [
    "# Projectile Range\n",
    "Suppose we have a projectile with which we want to hit some range. The formula for the range of a projectile is $R = \\frac{{v_0}^2 \\sin(2\\theta_0)}{g}$ and it shows that the maximum range depends on the square of initial velocity and the angle of launch. Let's assume that we don't know the phyiscs and we want to use regression to predict the maximum range. In our case, if the angle is between 50 and 60 degrees, we see maximum range and we get a maximum target 'y'. Similarly if the velocity is is between 90 and 100 arnitrary units, we observe the maximum range.\n",
    "\n",
    "The code cell right below creates the toy dataset you have to use to train and then test a regularized logistic regression model. Don't worry if you don't understand some parts of the code, it's using more advanced tools such as *pandas* and *scikit-learn*. Simply run the cell to obtain the \"x_train, x_test, y_train, y_test\" numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86b474-3454-4fdb-ba83-417a99df6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of experiments\n",
    "n = 15000\n",
    "\n",
    "# Generate random angles between 10 and 90 degrees\n",
    "angles = np.random.uniform(low=10, high=90, size=n)\n",
    "\n",
    "# Generate random initial velocities\n",
    "velocities = np.random.uniform(low=10, high=100, size=n)\n",
    "\n",
    "# Combine angles and velocities into a single 2D array (this will be our input features)\n",
    "X = np.column_stack((angles, velocities))\n",
    "\n",
    "# Generate target variable\n",
    "# For simplicity, let's say a hit is when angle is between 50 and 60 degrees and velocity is between 90 and 100 units\n",
    "y = [1 if (50 <= angle <= 60) and (90 <= velocity <= 100) else 0 for angle, velocity in zip(angles, velocities)]\n",
    "\n",
    "# Convert y to a numpy array\n",
    "y = np.array(y)\n",
    "\n",
    "# Balance the data sample: retain an equal number of hit and miss outcomes\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X, columns=['angle', 'velocity'])\n",
    "df['y'] = y\n",
    "df_sig = df[df['y']==1]\n",
    "df_back = df[df['y']==0].sample(n=df_sig.shape[0])\n",
    "df_balanced = pd.concat([df_sig, df_back])\n",
    "\n",
    "# Convert 'angle' and 'velocity' columns back to a 2D numpy array for X\n",
    "X = df_balanced[['angle', 'velocity']].values\n",
    "\n",
    "# Convert 'y' column back to a 1D numpy array for y\n",
    "y = df_balanced['y'].values\n",
    "\n",
    "# the code below prepares training and testing datasets for you (we will go over the sklearn package in the afternoon session)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=324, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44839042-f6fc-41b5-bd2b-888799b9ee49",
   "metadata": {},
   "source": [
    "In the cell below, define the cost function for a regularized logistic regression model that you will use to predict wether a given projectile hits the range or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebf067-0139-4951-b671-a8bb903316fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip( z, -500, 500 )           # protect against overflow\n",
    "    g = \n",
    "\n",
    "    return g\n",
    "\n",
    "def compute_cost_logistic(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n): Data, m examples with n features\n",
    "      y (ndarray (m,)): target values\n",
    "      w (ndarray (n,)): model parameters  \n",
    "      b (scalar)      : model parameter\n",
    "      lambda_ (scalar): Controls amount of regularization\n",
    "    Returns:\n",
    "      total_cost (scalar):  cost \n",
    "    \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6a686-8036-4ae7-8d6f-20e8d4fee831",
   "metadata": {},
   "source": [
    "In the cell below, define a function that computes the gradient for the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e667f41-1b8a-49af-b73a-ea4c557ca253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X (ndarray (m,n): Data, m examples with n features\n",
    "      y (ndarray (m,)): target values\n",
    "      w (ndarray (n,)): model parameters  \n",
    "      b (scalar)      : model parameter\n",
    "    Returns\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar)      : The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7188f0-8bf1-4430-89fe-05b2f7d2bc04",
   "metadata": {},
   "source": [
    "In the cell below, define a function that implements the gradient descent for the logistic regression model above. **Hint**: to check wether the algorithm converges, you may want to print the cost funtion value every few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c6752-e6b8-42c3-965d-fb63cb5c1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n)   : Data, m examples with n features\n",
    "      y (ndarray (m,))   : target values\n",
    "      w_in (ndarray (n,)): Initial values of model parameters  \n",
    "      b_in (scalar)      : Initial values of model parameter\n",
    "      alpha (float)      : Learning rate\n",
    "      num_iters (scalar) : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,))   : Updated values of parameters\n",
    "      b (scalar)         : Updated value of parameter \n",
    "    \"\"\"\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history \n",
    "    w = \n",
    "    b = \n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "                   \n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            \n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {}   \")\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ab634-5344-4346-bd7e-27d500a144d3",
   "metadata": {},
   "source": [
    "In the cell below, run the gradient descent for at least 10000 iterations to train the model. Use a regularization parameter lambda_ = 1.0, and a learning rate with a given value that gives you convergence. You may have to try a few times until you reach convergence. **Hint**: don't use a learning rate value smaller than $10^{-4}$, otherwise the convergence may become too slow with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6755cc-8173-48c8-beb7-c7c93da1d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tmp  = \n",
    "b_tmp  = \n",
    "alpha_ = \n",
    "lambda_ = 1.0\n",
    "iters = 10000\n",
    "\n",
    "w_out = gradient_descent() \n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a8fe2f-6ede-4148-8276-3c330a00d8b6",
   "metadata": {},
   "source": [
    "In the cell below, use your model to predict wether each of the entries in the 'x_test' array hits the target. You may then print the target values 'y_test' to see how well the model predicts the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81d07a-f88e-4d70-8137-df7e27ec0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid())\n",
    "print(\"The test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac32d8-7838-4d9f-a982-2ecbd6693984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
