{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe2ad27",
   "metadata": {},
   "source": [
    "Notebook basé sur le laboratoire du cours de Machine Learning d'Andrew Ng sur Coursera\n",
    "\n",
    "CRÉDIT : DeepLearning.AI https://www.deeplearning.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58272597",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "Dans ce laboratoire, vous allez :\n",
    "- automatiser le processus d'optimisation de $w$ et $b$ en utilisant la descente de gradient (gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca6a26",
   "metadata": {},
   "source": [
    "## Outils\n",
    "Dans ce TP, nous utiliserons :\n",
    "- NumPy, une bibliothèque populaire pour le calcul scientifique\n",
    "- Matplotlib, une bibliothèque populaire pour la visualisation de données\n",
    "- des fonctions de tracé dans le fichier `lab_utils.py` dans le répertoire local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09dfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "from lab_utils_uni import plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197caedd",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2\"></a>\n",
    "# Énoncé du problème\n",
    "\n",
    "Utilisons les mêmes deux points de données qu'avant - une maison de 1000 pieds carrés vendue pour \\\\$300,000 et une maison de 2000 pieds carrés vendue pour \\\\$500,000.\n",
    "\n",
    "| Taille (1000 pieds carrés) | Prix (milliers de dollars) |\n",
    "| ----------------| ------------------------ |\n",
    "| 1               | 300                      |\n",
    "| 2               | 500                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63892795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de notre set de données\n",
    "x_train = np.array([1.0, 2.0])   # caractéristiques\n",
    "y_train = np.array([300.0, 500.0])   # valeur cible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320a869",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.0.1\"></a>\n",
    "### Compute_Cost\n",
    "Ceci a été développé dans le dernier TP. Nous en aurons besoin à nouveau ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc878e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le coût\n",
    "def compute_cost(x, y, w, b):\n",
    "   \n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7a139",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.1\"></a>\n",
    "## Résumé de la descente de gradient\n",
    "Jusqu'à présent dans ce cours, vous avez développé un modèle linéaire qui prédit $f_{w,b}(x^{(i)})$ :\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
    "En régression linéaire, vous utilisez des données d'entraînement en entrée pour ajuster les paramètres $w$,$b$ en minimisant une mesure de l'erreur entre nos prédictions $f_{w,b}(x^{(i)})$ et les données réelles $y^{(i)}$. Cette mesure est appelée le $coût$, $J(w,b)$. Lors de l'entraînement, vous mesurez le coût sur tous nos échantillons d'entraînement $x^{(i)},y^{(i)}$\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51175b05",
   "metadata": {},
   "source": [
    "Dans le cours, la *descente de gradient* a été décrite comme suit :\n",
    "\n",
    "$$\\begin{align*} \\text{répéter}&\\text{ jusqu'à convergence :} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "où, les paramètres $w$, $b$ sont mis à jour simultanément.  \n",
    "Le gradient est défini comme suit :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Ici, *simultanément* signifie que vous calculez les dérivées partielles pour tous les paramètres avant de mettre à jour l'un des paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855f42f",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.2\"></a>\n",
    "## Implémenter la descente de gradient\n",
    "Vous allez implémenter l'algorithme de descente de gradient pour une seule caractéristique. Vous aurez besoin de trois fonctions. \n",
    "- `compute_gradient` implémentant l'équation (4) et (5) ci-dessus\n",
    "- `compute_cost` implémentant l'équation (2) ci-dessus (code du TP précédent)\n",
    "- `gradient_descent`, utilisant compute_gradient et compute_cost\n",
    "\n",
    "Conventions :\n",
    "- Le nommage des variables python contenant des dérivées partielles suit ce modèle, $\\frac{\\partial J(w,b)}{\\partial b}$ sera `dj_db`.\n",
    "- w.r.t signifie par rapport à, comme dans la dérivée partielle de $J(wb)$ par rapport à $b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2481e",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.3\"></a>\n",
    "### compute_gradient\n",
    "<a name='ex-01'></a>\n",
    "Écrivez dans la cellule ci-dessous une fonction `compute_gradient` qui implémente les équations (4) et (5) ci-dessus et qui renvoie $\\frac{\\partial J(w,b)}{\\partial w}$,$\\frac{\\partial J(w,b)}{\\partial b}$. Les commentaires intégrés décrivent les opérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Calcule le gradient pour la régression linéaire \n",
    "    Args:\n",
    "      x (ndarray (m,)): Données, m exemples \n",
    "      y (ndarray (m,)): valeurs cibles\n",
    "      w,b (scalaire)    : paramètres du modèle  \n",
    "    Returns\n",
    "      dj_dw (scalaire): Le gradient du coût par rapport aux paramètres w\n",
    "      dj_db (scalaire): Le gradient du coût par rapport au paramètre b     \n",
    "     \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e7bf3",
   "metadata": {},
   "source": [
    "Utilisons maintenant notre fonction `compute_gradient` pour trouver et tracer certaines dérivées partielles de notre fonction de coût par rapport à l'un des paramètres, $w_0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_gradients(x_train,y_train, compute_cost, compute_gradient)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b44a7f",
   "metadata": {},
   "source": [
    "Ci-dessus, le graphique de gauche montre $\\frac{\\partial J(w,b)}{\\partial w}$ ou la pente de la courbe de coût par rapport à $w$ en trois points. Sur le côté droit du graphique, la dérivée est positive, tandis que sur la gauche, elle est négative. En raison de la forme \"en bol\", les dérivées conduiront toujours la descente de gradient vers le bas où le gradient est nul.\n",
    "\n",
    "Le graphique de gauche a fixé $b=100$. La descente de gradient utilisera à la fois $\\frac{\\partial J(w,b)}{\\partial w}$ et $\\frac{\\partial J(w,b)}{\\partial b}$ pour mettre à jour les paramètres. Le 'quiver plot' sur la droite offre un moyen de visualiser le gradient des deux paramètres. La taille des flèches reflète l'ampleur du gradient à ce point. La direction et la pente de la flèche reflètent le rapport de $\\frac{\\partial J(w,b)}{\\partial w}$ et $\\frac{\\partial J(w,b)}{\\partial b}$ à ce point.\n",
    "Notez que le gradient pointe *à l'opposé* du minimum. Revoir l'équation (3) ci-dessus. Le gradient mis à l'échelle est *soustrait* de la valeur actuelle de $w$ ou $b$. Cela déplace le paramètre dans une direction qui réduira le coût."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c70fc",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.5\"></a>\n",
    "###  Descente de gradient\n",
    "Maintenant que les gradients peuvent être calculés, la descente de gradient, décrite dans l'équation (3) ci-dessus, peut être mise en œuvre ci-dessous dans une fonction `gradient_descent`. Les détails de l'implémentation sont décrits dans les commentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f76017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function): \n",
    "    \"\"\"\n",
    "    Effectue la descente de gradient pour ajuster w,b. Met à jour w,b en prenant \n",
    "    num_iters pas de gradient avec un taux d'apprentissage alpha\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,))  : Données, m exemples \n",
    "      y (ndarray (m,))  : valeurs cibles\n",
    "      w_in,b_in (scalaire): valeurs initiales des paramètres du modèle  \n",
    "      alpha (float):     Taux d'apprentissage\n",
    "      num_iters (int):   nombre d'itérations pour exécuter la descente de gradient\n",
    "      cost_function:     fonction à appeler pour produire le coût\n",
    "      gradient_function: fonction à appeler pour produire le gradient\n",
    "      \n",
    "    Returns:\n",
    "      w (scalaire): Valeur mise à jour du paramètre après l'exécution de la descente de gradient\n",
    "      b (scalaire): Valeur mise à jour du paramètre après l'exécution de la descente de gradient\n",
    "      J_history (List): Historique des valeurs de coût\n",
    "      p_history (list): Historique des paramètres [w,b] \n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dddb69",
   "metadata": {},
   "source": [
    "Ci-dessous, vous utiliserez cette fonction pour trouver les valeurs optimales de $w$ et $b$ sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiser les paramètres\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# quelques paramètres de descente de gradient\n",
    "iterations = 10000\n",
    "tmp_alpha = 1.0e-2\n",
    "# exécuter la descente de gradient\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "print(f\"(w,b) trouvés par descente de gradient: ({w_final:8.4f},{b_final:8.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131dd4a",
   "metadata": {},
   "source": [
    "Prenez un moment et notez certaines caractéristiques du processus de descente de gradient affiché ci-dessus.\n",
    "\n",
    "- Le coût commence grand et diminue rapidement comme décrit dans le matériel de cours.\n",
    "- Les dérivées partielles, `dj_dw`, et `dj_db` deviennent également plus petites, rapidement au début puis plus lentement. Comme le montre le diagramme du cours, lorsque le processus se rapproche du 'fond du bol', le progrès est plus lent en raison de la plus petite valeur de la dérivée à ce point.\n",
    "- le progrès ralentit bien que le taux d'apprentissage, alpha, reste fixe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15820cb6",
   "metadata": {},
   "source": [
    "### Coût versus itérations de la descente de gradient \n",
    "Un graphique du coût en fonction des itérations est une mesure utile de la progression de la descente de gradient. Le coût devrait toujours diminuer lors des exécutions réussies. Le changement de coût est si rapide initialement, qu'il est utile de tracer la descente initiale sur une échelle différente de la descente finale. Dans les graphiques ci-dessous, notez l'échelle du coût sur les axes et l'étape d'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd443cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracer le coût versus l'itération\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "ax1.plot(J_hist[:100])\n",
    "ax2.plot(1000 + np.arange(len(J_hist[1000:])), J_hist[1000:])\n",
    "ax1.set_title(\"Coût vs. itération (début)\");  ax2.set_title(\"Coût vs. itération (fin)\")\n",
    "ax1.set_ylabel('Coût')            ;  ax2.set_ylabel('Coût') \n",
    "ax1.set_xlabel('étape d\\'itération')  ;  ax2.set_xlabel('étape d\\'itération') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f0f91",
   "metadata": {},
   "source": [
    "### Prédictions\n",
    "Maintenant que vous avez découvert les valeurs optimales pour les paramètres $w$ et $b$, vous pouvez maintenant utiliser le modèle pour prédire les valeurs des logements en fonction de nos paramètres appris. Comme prévu, les valeurs prédites sont presque les mêmes que les valeurs d'entraînement pour le même logement. De plus, la valeur non présente dans la prédiction est conforme à la valeur attendue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prédiction pour une maison de 1000 pieds carrés {w_final*1.0 + b_final:0.1f} mille dollars\")\n",
    "print(f\"Prédiction pour une maison de 1200 pieds carrés {w_final*1.2 + b_final:0.1f} mille dollars\")\n",
    "print(f\"Prédiction pour une maison de 2000 pieds carrés {w_final*2.0 + b_final:0.1f} mille dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f34bee",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.6\"></a>\n",
    "## Tracé\n",
    "Vous pouvez montrer la progression de la descente de gradient pendant son exécution en traçant le coût sur les itérations sur un tracé de contour du coût(w,b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d86a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
    "plt_contour_wgrad(x_train, y_train, p_hist, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805837e",
   "metadata": {},
   "source": [
    "Ci-dessus, le tracé de contour montre le $coût(w,b)$ sur une plage de $w$ et $b$. Les niveaux de coût sont représentés par les anneaux. Superposé, à l'aide de flèches rouges, se trouve le chemin de la descente de gradient. Voici quelques points à noter :\n",
    "- Le chemin fait des progrès réguliers (monotones) vers son objectif.\n",
    "- Les premiers pas sont beaucoup plus grands que les pas près de l'objectif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b4075",
   "metadata": {},
   "source": [
    "**En zoomant**, nous pouvons voir les dernières étapes de la descente de gradient. Notez que la distance entre les étapes se réduit à mesure que le gradient approche de zéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0252f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "plt_contour_wgrad(x_train, y_train, p_hist, ax, w_range=[180, 220, 0.5], b_range=[80, 120, 0.5],\n",
    "            contours=[1,5,10,20],resolution=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e9415",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.7.1\"></a>\n",
    "### Augmentation du taux d'apprentissage\n",
    "\n",
    "Dans la conférence, il y a eu une discussion sur la valeur appropriée du taux d'apprentissage, $\\alpha$ dans l'équation(3). Plus $\\alpha$ est grand, plus la descente de gradient convergera rapidement vers une solution. Mais, s'il est trop grand, la descente de gradient divergera. Ci-dessus, vous avez un exemple de solution qui converge bien.\n",
    "\n",
    "Essayons d'augmenter la valeur de $\\alpha$ et voyons ce qui se passe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiser les paramètres\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# définir alpha à une grande valeur\n",
    "iterations = 10\n",
    "tmp_alpha = 8.0e-1\n",
    "# exécuter la descente de gradient\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43e39f",
   "metadata": {},
   "source": [
    "Ci-dessus, $w$ et $b$ oscillent entre des valeurs positives et négatives, la valeur absolue augmentant à chaque itération. De plus, à chaque itération $\\frac{\\partial J(w,b)}{\\partial w}$ change de signe et le coût augmente plutôt que de diminuer. C'est un signe clair que le *taux d'apprentissage est trop grand* et que la solution diverge.\n",
    "Visualisons cela avec un graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_divergence(p_hist, J_hist,x_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d078708",
   "metadata": {},
   "source": [
    "Ci-dessus, le graphique de gauche montre la progression de $w$ lors des premières étapes de la descente de gradient. $w$ oscille de positif à négatif et le coût augmente rapidement. La descente de gradient opère simultanément sur $w$ et $b$, donc on a besoin du graphique 3D à droite pour avoir une image complète."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4887b",
   "metadata": {},
   "source": [
    "## Félicitations !\n",
    "Dans ce TP, vous avez :\n",
    "- approfondi les détails de la descente de gradient pour une seule variable.\n",
    "- développé une fonction pour calculer le gradient\n",
    "- visualisé ce qu'est le gradient\n",
    "- complété une fonction de descente de gradient\n",
    "- utilisé la descente de gradient pour trouver des paramètres\n",
    "- examiné l'impact de la taille du taux d'apprentissage"
   ]
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "40291"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
