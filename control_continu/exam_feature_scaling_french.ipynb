{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf03537",
   "metadata": {},
   "source": [
    "# Objectif de l'examen\n",
    "Cet examen simule des données de temps et d'impulsion' avec pour objectif de prédire la force. La force, définie comme ($F = 5 \\times t + 0.002 * p$), est ajoutée comme label. Du bruit aléatoire a également été ajouté aux valeurs de force afin de rendre le problème plus réaliste.\n",
    "Supposons que vous ne connaissez pas a priori les constantes de proportionnalité qui, à partir de l'impulsion et du temps, vous donnent la force dans ce cas spécifique, et utilisez la régression linéaire pour prédire la force à partir des données disponibles.\n",
    "\n",
    "L'objectif de l'examen est de montrer que la mise à échelle des caractéristiques aide à améliorer les performances d'un modèle de régression. Comme dans le cours, vous avez vu la normalisation du score z, vous devriez donc l'utiliser pour montrer qu'une prédiction de modèle sur les données de test s'améliore si le modèle est entraîné et testé sur des caractéristiques normalisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e456264",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, des données sont générées et ensuite divisées en set d’entraînement et de test.\n",
    "Vous devrez utiliser ces deux sets de données durant la suite de l'examen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604dfe1-ce48-4de3-b10a-c4d467b4bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# On génère des données pour le temps, l'impulsion et la force\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "time = np.random.uniform(0, 1, num_samples)\n",
    "momentum = np.random.uniform(0, 1000, num_samples)\n",
    "force = 5 * time + 0.002 * momentum + np.random.normal(0, 1, num_samples)\n",
    "\n",
    "# On sépare les données en un set d'entraînement et un set de test\n",
    "X_ = np.column_stack((time, momentum))\n",
    "y_ = force\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6bbaf",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, implémentez la fonction de coût pour la régression linéaire, y compris un terme de régularisation lambda_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8b98d-d4e4-4b10-b1a0-553ed20f4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(    ):\n",
    "    \"\"\"\n",
    "    Calcule la fonction de coût pour la régression linéaire sur tous les exemples\n",
    "    Args:\n",
    "      X (ndarray (m,n)  : données, m exemples avec n caractéristiques\n",
    "      y (ndarray (m,))  : valeurs cibles\n",
    "      w (ndarray (n,))  : paramètres du modèle  \n",
    "      b (scalaire)      : paramètre du modèle\n",
    "      lambda_ (scalaire): contrôle la quantité de régularisation\n",
    "    Returns:\n",
    "      total_cost (scalaire):  coût \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbfcd6",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, implémentez la fonction de coût pour la régression linéaire, y compris un terme de régularisation lambda_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(    ): \n",
    "    \"\"\"\n",
    "    Calcule le gradient pour la régression linéaire\n",
    " \n",
    "    Args:\n",
    "      X (ndarray (m,n): Données, m exemples avec n caractéristiques\n",
    "      y (ndarray (m,)): valeurs cibles\n",
    "      w (ndarray (n,)): paramètres du modèle  \n",
    "      b (scalaire)    : paramètre du modèle\n",
    "    Returns\n",
    "      dj_dw (ndarray (n,)): Le gradient du coût par rapport aux paramètres w. \n",
    "      dj_db (scalaire)    : Le gradient du coût par rapport au paramètre b. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff88b3",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, l'algorithme de descente de gradient vous est fourni. Assurez-vous que votre implémentation des fonctions de coût et de gradient est compatible avec le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01014bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters, lambda_):\n",
    "    \"\"\"\n",
    "    Effectue la descente de gradient en batch\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n)   : Données, m exemples avec n caractéristiques\n",
    "      y (ndarray (m,))   : valeurs cibles\n",
    "      w_in (ndarray (n,)): Valeurs initiales des paramètres du modèle  \n",
    "      b_in (scalaire)    : Valeurs initiales du paramètre du modèle\n",
    "      alpha (float)      : Taux d'apprentissage\n",
    "      num_iters (scalaire) : nombre d'itérations pour exécuter la descente de gradient\n",
    "      lambda_ (scalaire)   : paramètre de régularisation pour la fonction de coût\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,))   : Valeurs mises à jour des paramètres\n",
    "      b (scalaire)       : Valeur mise à jour du paramètre \n",
    "    \"\"\"\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculez le gradient et mettez à jour les paramètres\n",
    "        dj_db, dj_dw = compute_gradient(X, y, w, b )\n",
    "\n",
    "        # Mettre à jour les paramètres en utilisant w, b, alpha et gradient\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "      \n",
    "        # Enregistrez le coût J à chaque itération\n",
    "        if i<100000:      \n",
    "            J_history.append( compute_cost(X, y, w, b, lambda_) )\n",
    "\n",
    "        # Afficher le coût toutes les 10 itérations ainsi que les dix dernières itérations < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Coût {J_history[-1]}   \")\n",
    "        \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2b5b3",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, initialisez correctement les paramètres du modèle et appelez la fonction de descente de gradient sur 1000 itérations. Le paramètre de régularisation est fixé à lambda_ = 0.1 et vous est donné, tandis que vous devez trouver une valeur du taux d'apprentissage alpha_ dans l'intervalle entre $10^{-4}$ et $10^{-8}$ qui assure la convergence de l'algorithme de descente de gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4122d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entraînement et test avant la mise à l'échelle des caractéristiques\n",
    "w_tmp  = \n",
    "b_tmp  = \n",
    "# trouver une valeur alpha_ entre 10^-4 et 10^-8 qui assure la convergence pour la descente de gradient\n",
    "alpha_ = \n",
    "# pas besoin de changer lambda_ ou iters\n",
    "lambda_ = 0.1\n",
    "iters = 1000\n",
    "\n",
    "# appelez la fonction de descente de gradient ci-dessous sur l'ensemble de données d'entraînement, en utilisant les arguments que vous venez d'initialiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2c7f9",
   "metadata": {},
   "source": [
    "Complétez la cellule ci-dessous afin que \"y_pred\" stocke les prédictions du modèle pour l'ensemble de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34b396-7516-406c-bf41-851710ebe266",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec372133",
   "metadata": {},
   "source": [
    "Calculez le coût pour les X_test en utilisant lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3addc5",
   "metadata": {},
   "source": [
    "Vous devriez obtenir quelque chose comme 4.057513207508225"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192ed50",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, définissez une fonction qui implémente la normalisation du score $z$ pour les caractéristiques du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef21aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    calcule X, normalisé par le score z par colonne\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : données d'entrée, m exemples, n caractéristiques\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): entrée normalisée par colonne\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c407cf",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, utilisez la normalisation du score $z$ que vous avez implémentée ci-dessus pour obtenir les ensembles de données d'entraînement (\"X_train_norm\") et de test (\"X_test_norm\") mis à l'échelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = \n",
    "X_test_norm = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadfe02",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, appelez la fonction de descente de gradient pour 1000 itérations en utilisant les ensembles de données d'entraînement (\"X_train_norm\") et de test (\"X_test_norm\") mis à l'échelle. Le paramètre de régularisation est fixé à lambda_ = 0.1 et vous est donné. **De plus, le taux d'apprentissage alpha_ dans ce cas a été changé à alpha_ = 0.01 et vous est donné** : vous n'avez pas besoin de changer sa valeur. C'est parce que la mise à l'échelle des caractéristiques aide à la convergence et vous permet d'utiliser un taux d'apprentissage plus élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# données d'entraînement et de test après la mise à l'échelle des caractéristiques\n",
    "w_tmp  = \n",
    "b_tmp  = \n",
    "# pas besoin de changer alpha_, lambda_, iters\n",
    "alpha_ = 0.01 \n",
    "lambda_ = 0.1\n",
    "iters = 1000\n",
    "\n",
    "# appelez la fonction de descente de gradient ci-dessous sur l'ensemble de données d'entraînement, en utilisant les caractéristiques mises à l'échelle et les arguments que vous venez d'initialiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579235b9",
   "metadata": {},
   "source": [
    "Complétez la cellule ci-dessous afin que \"y_pred_xnorm\" stocke les prédictions du modèle pour l'ensemble de données de test en utilisant les caractéristiques **mises à l'échelle** que vous avez précédemment calculées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08677db1-4ac5-4272-96ea-44a0a98f65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xnorm = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb4178",
   "metadata": {},
   "source": [
    "Enfin, exécutez la cellule ci-dessous pour obtenir la MSE de votre modèle après la mise à l'échelle des caractéristiques. Vous vous attendez à obtenir une valeur nettement plus petite que celle que vous avez précédemment obtenue en entraînant l'ensemble de données sur les caractéristiques originales, avant la normalisation du score $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c3dac",
   "metadata": {},
   "source": [
    "Calculez à nouveau la fonction de coût pour X_test_norm en utilisant lambda_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ac743",
   "metadata": {},
   "source": [
    "Cette fois, le coût devrait être plus bas et devrait être approximativement 0.949801563674332"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
