{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab733aa",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "Ce TP vous présente les dataframes pandas et leurs utilisations. Vous pouvez consulter la <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\">documentation</a> de pandas pour en savoir plus sur leurs différentes fonctionnalités.\n",
    "\n",
    "Il vous présente également différentes méthodes de transformation des données. De plus, quelques exemples d'analyse de précision et de lissage de tendance sont montrés ici.\n",
    "\n",
    "On s'attend à ce que vous lisiez le code et compreniez comment il fonctionne, puis que vous le complétiez si nécessaire en suivant les suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e13607",
   "metadata": {},
   "source": [
    "# Transformation à la Racine Carrée (Sqrt Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350a247",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, les données mensuelles australiennes sur l'électricité sont chargées, et la méthode de transformation sqrt est appliquée. Le tracé temporel des données transformées est montré, puis un histogramme correspondant est également extrait, pour mettre en évidence les changements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8425aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "from pandas import DataFrame\n",
    "from pandas import read_excel\n",
    "from matplotlib import pyplot\n",
    "series = read_excel('Electricity.xls',\n",
    "              sheet_name='Data', header=0,\n",
    "              index_col=0, parse_dates=True)\n",
    "dataframe = DataFrame(series.values)\n",
    "dataframe.columns = ['electricity']\n",
    "\n",
    "# sqrt transformation est appliqué:\n",
    "dataframe['electricity'] = sqrt(dataframe['electricity'])\n",
    "pyplot.figure(1)\n",
    "# line plot\n",
    "pyplot.subplot(211)\n",
    "pyplot.plot(dataframe['electricity'])\n",
    "# histogramme\n",
    "pyplot.subplot(212)\n",
    "pyplot.hist(dataframe['electricity'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1365e",
   "metadata": {},
   "source": [
    "# Transformation logarithmique (Log Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94351b5",
   "metadata": {},
   "source": [
    "De manière similaire, la transformation logarithmique est appliquée et le tracé temporel et l'histogramme sont montrés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10698b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "series = read_excel('Electricity.xls',\n",
    "              sheet_name='Data', header=0,\n",
    "              index_col=0, parse_dates=True)\n",
    "dataframe = DataFrame(series.values)\n",
    "dataframe.columns = ['electricity']\n",
    "dataframe['electricity'] = log(dataframe['electricity'])\n",
    "pyplot.figure(1)\n",
    "# line plot\n",
    "pyplot.subplot(211)\n",
    "pyplot.plot(dataframe['electricity'])\n",
    "# histogram\n",
    "pyplot.subplot(212)\n",
    "pyplot.hist(dataframe['electricity'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397bc60",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessous, veuillez utiliser la méthode `hist` de pandas (la documentation est <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html\">ici</a>) pour tracer la colonne \"électricité\" pour le dataframe chargé dans la cellule ci-dessus. Comparez-le avec ce que vous avez obtenu ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79468155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194e0ab",
   "metadata": {},
   "source": [
    "Ci-dessous, convertissez la colonne \"électricité\" du précédent dataframe pandas en un tableau numpy (vous avez vu comment faire la semaine dernière), puis appliquez la normalisation z-score comme vous l'avez appris lorsque nous avons discuté de la mise à l'échelle des caractéristiques. Tracez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496b3cd",
   "metadata": {},
   "source": [
    "# Ajustements de calendrier\n",
    "Si les données sont pour des mois calendaires, alors il peut être nécessaire de tenir compte de la longueur d'un mois. La différence entre le mois le plus long et le plus court est d'environ $\\frac{(31- 28)}{30} = 10\\%$. L'ajustement nécessaire est\n",
    "\n",
    "$$\n",
    "W_t = \\frac{\\text{\\# de jours dans un mois moyen}}{\\text{\\# de jours dans le mois } i} \\times Y_t = \\frac{365.25/12}{\\text{\\# de jours dans le mois } i} \\times Y_t\n",
    "$$\n",
    "\n",
    "Le code ci-dessous charge les données originales et ajustées à partir d'une feuille de calcul Excel contenant des données de production de lait, et les trace l'une sur l'autre. Ouvrez la feuille de calcul Excel et vérifiez manuellement comment l'ajustement a été calculé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = read_excel('MilkProduction.xls',\n",
    "              sheet_name='AdjustedData', header=0,\n",
    "              index_col=0, parse_dates=True)  # vous pouvez inclure d'autres paramètres\n",
    "series.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d82182",
   "metadata": {},
   "source": [
    "# Analyse de la précision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b52f6",
   "metadata": {},
   "source": [
    "Le prévisionniste doit choisir le meilleur modèle à utiliser pour prévoir une série temporelle particulière. Nous discutons ici différentes mesures pour comparer différents modèles de prévision sur la base des erreurs de prévision. Soit $F_t$ la valeur prévue et $Y_t$ l'observation réelle à l'instant $t$. Alors l'erreur de prévision à l'instant $t$ est définie comme $e_t = Y_t - F_t$.\n",
    "\n",
    "Habituellement, $F_t$ est calculé à partir des valeurs précédentes de $Y_t$ jusqu'à et y compris la valeur précédente immédiate $Y_{t-1}$. Ainsi, $F_t$ ne prédit qu'un pas en avant. Dans ce cas, $F_t$ est appelé la **prévision à un pas** et $e_t$ est appelé l'**erreur de prévision à un pas**. Habituellement, nous évaluons l'erreur non pas à partir d'une telle $e_t$ mais à partir de $n$ valeurs. Trois mesures de l'erreur sont :\n",
    "\n",
    "* **Erreur Moyenne (ME)** :\n",
    "$$\n",
    "ME = \\frac{1}{n} \\sum_{t=1}^{n} e_t\n",
    "$$\n",
    "\n",
    "* **Erreur Absolue Moyenne (MAE)** :\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{t=1}^{n} |e_t|\n",
    "$$\n",
    "\n",
    "* **Erreur Quadratique Moyenne (MSE)** :\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{t=1}^{n} e_t^2\n",
    "$$\n",
    "\n",
    "Ci-dessous, les données de production de bière australienne sont analysées, en chargeant les prévisions de deux méthodes de prévision étiquetées respectivement NF1 et NF2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AustralianBeer  = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols = [1],\n",
    "                             header=0,  dtype=float)\n",
    "AustralianBeer = AustralianBeer['Original Data']\n",
    "NaiveF1  = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols = [2],\n",
    "                      header=0,  dtype=float)\n",
    "NaiveF1 = NaiveF1['NF1']\n",
    "NaiveF2 = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols=[3],\n",
    "                     header=0,  dtype=float)\n",
    "NaiveF2 = NaiveF2['NF2']\n",
    "\n",
    "# Tracé des données originales et des prévisions NF1\n",
    "AustralianBeer.plot(legend=True)\n",
    "NaiveF1.plot(legend=True)\n",
    "pyplot.show()\n",
    "\n",
    "# Tracé des données originales et des prévisions NF2\n",
    "AustralianBeer.plot(legend=True)\n",
    "NaiveF2.plot(legend=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868692fc",
   "metadata": {},
   "source": [
    "Complétez la cellule ci-dessous pour calculer l'erreur pour les modèles \"NaiveF1\" et \"NaiveF2\" par rapport aux données originales \"AustralianBeer\", puis calculez le ME, MAE, MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d388616-d852-4493-bd19-3970e6cfe671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez le code\n",
    "Error1 = \n",
    "Error2 = \n",
    "ME1 = \n",
    "ME2 = \n",
    "MAE1=\n",
    "MAE2=\n",
    "MSE1=\n",
    "MSE2="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef83253",
   "metadata": {},
   "source": [
    "De même, les erreurs en pourcentage sont calculées ci-dessous, puis toutes les erreurs sont affichées sous forme de tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5ed08-77ff-4af1-8f05-877705d38e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PercentageError1=(Error1/AustralianBeer)*100\n",
    "PercentageError2=(Error2/AustralianBeer)*100\n",
    "MPE1 = sum(PercentageError1)* 1.0/len(NaiveF1)\n",
    "MPE2 = sum(PercentageError2)* 1.0/len(NaiveF2)\n",
    "MPAE1= sum(abs(PercentageError1))*1.0/len(NaiveF1)\n",
    "MPAE2= sum(abs(PercentageError2))*1.0/len(NaiveF2)\n",
    "\n",
    "\n",
    "# Affichage d'un résumé des erreurs sous forme de tableau\n",
    "print('Résumé des erreurs résultant de NF1 & NF2:')\n",
    "import pandas as pd\n",
    "cars = {'Errors': ['ME','MAE','MSE','MPE', 'MAPE'],\n",
    "        'NF1': [ME1, MAE1, MSE1, MPE1, MPAE1],\n",
    "        'NF2': [ME2, MAE2, MSE2, MPE2, MPAE2]\n",
    "        }\n",
    "AllErrors = pd.DataFrame(cars, columns = ['Errors', 'NF1', 'NF2'])\n",
    "print(AllErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2edc2",
   "metadata": {},
   "source": [
    "# ACF de l'erreur de prévision\n",
    "Il est souvent utile de considérer les erreurs de prévision à un pas comme une série temporelle à part entière, et de calculer et de tracer la fonction d'autocorrélation (ACF) de cette série. Comme mentionné ci-dessus dans le contexte des erreurs, on voudrait que les erreurs générées par une méthode de prévision soient complètement aléatoires. Si ce n'est pas le cas, l'ACF peut conserver certains motifs observables dans l'ensemble de données original. Par conséquent, avoir une ACF non complètement aléatoire peut être une indication que la méthode de prévision n'est pas nécessairement précise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AustralianBeer  = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols = [1],\n",
    "                             header=0,  dtype=float)\n",
    "AustralianBeer =AustralianBeer['Original Data']\n",
    "\n",
    "NaiveF1  = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols = [2],\n",
    "                      header=0, dtype=float)\n",
    "NaiveF1 = NaiveF1['NF1']\n",
    "\n",
    "NaiveF2 = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols=[3],\n",
    "                     header=0, dtype=float)\n",
    "NaiveF2 = NaiveF2['NF2']\n",
    "\n",
    "# Affichage des données originales\n",
    "AustralianBeer.plot(label='Original data', legend=True)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# Evaluation des erreurs des deux méthodes NF1 et NF2\n",
    "Error1 = AustralianBeer - NaiveF1\n",
    "Error2 = AustralianBeer - NaiveF2\n",
    "\n",
    "\n",
    "# Graphique de la série temporelle des erreurs\n",
    "Error1.plot(label='NF1 error plot', legend=True)\n",
    "Error2.plot(label='NF2 error plot', legend=True)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# Création d'un graphique d'autocorrélation\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(Error1)\n",
    "autocorrelation_plot(Error2)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea81702",
   "metadata": {},
   "source": [
    "# Intervalle de Prédiction\n",
    "\n",
    "En supposant que les erreurs sont normalement distribuées, on peut utilement évaluer la précision d'une prévision en utilisant le MSE (Mean Squared Error) comme une estimation de l'erreur. Un intervalle de prédiction approximatif pour la prochaine observation est :\n",
    "\n",
    "$$F_{t+1} ± z \\sqrt{MSE},$$\n",
    "\n",
    "où $z$ est un quantile de la distribution normale. Les valeurs typiques utilisées sont :\n",
    "\n",
    "| $z$   | Probabilité |\n",
    "|-------|-------------|\n",
    "| 1.282 | 0.80        |\n",
    "| 1.645 | 0.90        |\n",
    "| 1.960 | 0.95        |\n",
    "| 2.576 | 0.99        |\n",
    "\n",
    "Cela permet, par exemple, de mettre en place des intervalles de confiance de 95% ou 99% pour toute prévision.\n",
    "\n",
    "Dans la cellule ci-dessous, la première colonne de la feuille \"NF1NF2\" est chargée en utilisant l'argument `usecols` de la fonction 'read_excel', récupérant les données originales \"AustralianBeer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b10e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "AustralianBeer  = read_excel('BeerErrorsData.xls', sheet_name='NF1NF2', usecols = [1],\n",
    "                             header=0,  dtype=float)\n",
    "AustralianBeer = AustralianBeer['Original Data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e6751",
   "metadata": {},
   "source": [
    "Maintenant, en suivant les exemples ci-dessus, chargez d'abord la deuxième colonne, puis la troisième colonne, et attribuez-les respectivement aux dataframes \"NaiveF1\" et \"NaiveF2\". Assurez-vous en ouvrant la feuille de calcul que vous chargez la bonne colonne dans le dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289745a5-d60c-424b-b71b-24ff2d16a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez le code\n",
    "NaiveF1 = read_excel()\n",
    "NaiveF1 = \n",
    "NaiveF2 = read_excel()\n",
    "NaiveF2 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770d69a",
   "metadata": {},
   "source": [
    "Enfin, calculez l'intervalle de confiance de 0.90 (donc, z=1.645) pour les prévisions \"NaiveF1\" et \"NaiveF2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5ef2f-e96b-4a94-abb2-0e21cd988d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez le code\n",
    "Error1 = \n",
    "Error2 = \n",
    "MSE1=\n",
    "MSE2=\n",
    "\n",
    "LowerForecast1 = NaiveF1 - \n",
    "UpperForecast1 = NaiveF1 + \n",
    "\n",
    "LowerForecast2 = NaiveF2 - \n",
    "UpperForecast2 = NaiveF2 + "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67944f1",
   "metadata": {},
   "source": [
    "Les résultats sont ensuite tracés ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba1a57-2090-496e-b957-32a8d9e5444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graphique des données originales et des prévisions NF1\n",
    "AustralianBeer.plot(label='Original data')\n",
    "NaiveF1.plot(label='NF1 forecast')\n",
    "LowerForecast1.plot(label='NF1 lower bound')\n",
    "UpperForecast1.plot(label='NF1 upper bound')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# Graphique des données originales et des prévisions NF2\n",
    "AustralianBeer.plot(label='Original data')\n",
    "NaiveF2.plot(label='NF2 forecast')\n",
    "LowerForecast2.plot(label='NF2 lower bound')\n",
    "UpperForecast2.plot(label='NF2 upper bound')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32675b7",
   "metadata": {},
   "source": [
    "# Lissage exponentiel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc8213",
   "metadata": {},
   "source": [
    "# Lissage Exponentiel Simple\n",
    "\n",
    "La prévision exponentielle simple ou le lissage exponentiel simple (SES) est défini comme suit :\n",
    "\n",
    "$$F_{t+1} = \\alpha Y_t + (1 - \\alpha)F_t$$\n",
    "\n",
    "où $\\alpha$ est une valeur de poids donnée à sélectionner sous réserve que $0 \\leq \\alpha \\leq 1$. Ainsi, $F_{t+1}$ est la moyenne pondérée de l'observation actuelle, $Y_t$, avec la prévision, $F_t$, faite au moment précédent $t - 1$.\n",
    "\n",
    "L'application répétée de la formule donne :\n",
    "\n",
    "$$F_{t+1} = (1 - \\alpha)^t F_1 + \\alpha \\sum_{j=0}^{t-1} (1 - \\alpha)^j Y_{t-j}$$\n",
    "\n",
    "montrant que la dépendance de la prévision actuelle sur $Y_t$, $Y_{t-1}$, $Y_{t-2}$, ..., disparaît de manière exponentielle. Le taux auquel cette dépendance disparaît est contrôlé par $\\alpha$. Plus la valeur de $\\alpha$ est grande, plus la dépendance sur les valeurs précédentes disparaît rapidement.\n",
    "\n",
    "SES doit être initialisé. Un choix simple est d'utiliser $F_1 = Y_1$. D'autres valeurs sont possibles, mais nous ne nous attarderons pas trop sur ce point car nous sommes plus préoccupés par le comportement de la prévision une fois qu'elle a été utilisée pendant un certain temps.\n",
    "\n",
    "Il convient de noter que, comme avec les méthodes de moyennage, SES ne peut produire qu'une prévision à un pas.\n",
    "\n",
    "Ci-dessous, les données de vente de shampooing sont chargées et analysées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "series = read_excel('ShampooSales.xls', sheet_name='Data', header=0,\n",
    "              index_col=0, parse_dates=True)\n",
    "series.index.freq = 'MS'\n",
    "\n",
    "# Lissage Exponentiel Simple\n",
    "\n",
    "## SES model 1: alpha = 0.1\n",
    "fit1 = SimpleExpSmoothing(series).fit(smoothing_level=0.1,optimized=False)\n",
    "fcast1 = fit1.forecast(10).rename(r'$\\alpha=0.1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee05858",
   "metadata": {},
   "source": [
    "Ci-dessous, définissez \"fit2\" en utilisant alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57240b44-f231-4344-b509-ecdbc4167369",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SES model 2: alpha = 0.7\n",
    "fit2 = \n",
    "fcast2 = fit2.forecast(10).rename(r'$\\alpha=0.7$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f31c9",
   "metadata": {},
   "source": [
    "Enfin, nous montrons un exemple d'alpha sélectionné automatiquement par le logiciel d'optimisation intégré, et nous traçons les trois méthodes de prévision avec les données originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389f5c0-78e7-452d-816e-10894e5b1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modèle SES 3 : alpha sélectionné automatiquement par le logiciel d'optimisation intégré\n",
    "fit3 = SimpleExpSmoothing(series).fit()\n",
    "fcast3 = fit3.forecast(10).rename(r'$\\alpha=%s$'%fit3.model.params['smoothing_level'])\n",
    "\n",
    "\n",
    "# Graphique des données originales\n",
    "series.plot(color='black', legend=True)\n",
    "\n",
    "\n",
    "# Graphique des valeurs ajustées et des prévisions des 10 prochaines valeurs, respectivement, pour les trois modèles\n",
    "fit1.fittedvalues.plot(color='blue')\n",
    "fcast1.plot(color='blue', legend=True)\n",
    "fit2.fittedvalues.plot(color='red')\n",
    "fcast2.plot(color='red', legend=True)\n",
    "fcast3.plot(color='green', legend=True)\n",
    "fit3.fittedvalues.plot(color='green')\n",
    "pyplot.show()\n",
    "\n",
    "# Evaluation des erreurs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE1=mean_squared_error(fit1.fittedvalues, series)\n",
    "MSE2=mean_squared_error(fit2.fittedvalues, series)\n",
    "MSE3=mean_squared_error(fit3.fittedvalues, series)\n",
    "\n",
    "print('Summary of errors resulting from SES models 1, 2 & 3:')\n",
    "import pandas as pd\n",
    "cars = {'Model': ['MSE'],\n",
    "        'SES model 1': [MSE1],\n",
    "        'SES model 2': [MSE2],\n",
    "        'SES model 3': [MSE3]\n",
    "        }\n",
    "AllErrors = pd.DataFrame(cars, columns = ['Model', 'SES model 1', 'SES model 2', 'SES model 3'])\n",
    "print(AllErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763283f",
   "metadata": {},
   "source": [
    "# Lissage Exponentiel Linéaire de Holt\n",
    "\n",
    "La méthode de Holt, également connue sous le nom de méthode exponentielle linéaire (LES), a été introduite par Charles Holt en 1957. Il s'agit d'une extension de la méthode de lissage exponentiel simple/unique pour prendre en compte une éventuelle tendance linéaire (locale). La tendance permet de prévoir m périodes de temps à l'avance.\n",
    "\n",
    "Il y a deux constantes de lissage $\\alpha$ et $\\beta$, $0 \\leq \\alpha, \\beta \\leq 1$. Les équations sont :\n",
    "\n",
    "$$L_t = \\alpha Y_t + (1 - \\alpha)(L_{t-1} + b_{t-1})$$\n",
    "$$b_t = \\beta (L_t - L_{t-1}) + (1 - \\beta)b_{t-1}$$\n",
    "$$F_{t+m} = L_t + b_t m$$\n",
    "\n",
    "Ici, $L_t$ et $b_t$ sont respectivement des estimations (lissées exponentiellement) du niveau et de la tendance linéaire de la série au temps t, tandis que $F_{t+m}$ est la prévision linéaire à partir de t.\n",
    "\n",
    "Des estimations initiales sont nécessaires pour $L_1$ et $b_1$. Des choix simples sont $L_1 = Y_1$ et $b_1 = 0$. Cependant, si zéro est atypique de la pente initiale, alors une estimation plus prudente de la pente peut être nécessaire pour s'assurer que les prévisions initiales ne sont pas trop mauvaises.\n",
    "\n",
    "Il convient de noter que pour utiliser cette méthode, il n'est **pas** nécessaire qu'une série soit complètement linéaire, mais une certaine tendance doit être présente.\n",
    "\n",
    "Ci-dessous, les mêmes données de vente de shampooing de l'exemple précédent sont chargées et analysées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "series = read_excel('ShampooSales.xls', sheet_name='Data', header=0,\n",
    "              index_col=0)\n",
    "series.index.freq = 'MS'\n",
    "\n",
    "# Holt model 1: alpha = 0.8, beta=0.2\n",
    "fit1 = Holt(series).fit(smoothing_level=0.8, smoothing_trend=0.2, optimized=False)\n",
    "fcast1 = fit1.forecast(12).rename(\"Holt's linear trend\")\n",
    "\n",
    "fit2 = Holt(series, exponential=True).fit(smoothing_level=0.8, smoothing_trend=0.2, optimized=False)\n",
    "fcast2 = fit2.forecast(12).rename(\"Exponential trend\")\n",
    "\n",
    "fit3 = Holt(series, damped_trend=True).fit(smoothing_level=0.8, smoothing_trend=0.2)\n",
    "fcast3 = fit3.forecast(12).rename(\"Additive damped trend\")\n",
    "\n",
    "fit4 = Holt(series).fit(optimized=True)\n",
    "fcast4 = fit4.forecast(12).rename(\"Additive 2 damped trend\")\n",
    "\n",
    "\n",
    "# Graphique des données originales et les quatre méthodes de prévision\n",
    "series.plot(color='black', legend=True)\n",
    "fit1.fittedvalues.plot(color='blue')\n",
    "fcast1.plot(color='blue', legend=True)\n",
    "fit2.fittedvalues.plot(color='red')\n",
    "fcast2.plot(color='red', legend=True)\n",
    "fit3.fittedvalues.plot(color='green')\n",
    "fcast3.plot(color='green', legend=True)\n",
    "fcast4.plot(color='yellow', legend=True)\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "# Evaluation des erreurs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE1=mean_squared_error(fit1.fittedvalues, series)\n",
    "MSE2=mean_squared_error(fit2.fittedvalues, series)\n",
    "MSE3=mean_squared_error(fit3.fittedvalues, series)\n",
    "\n",
    "print('Summary of errors resulting from SES models 1, 2 & 3:')\n",
    "import pandas as pd\n",
    "cars = {'Model': ['MSE'],\n",
    "        'LES model 1': [MSE1],\n",
    "        'LES model 2': [MSE2],\n",
    "        'LES model 3': [MSE3]\n",
    "        }\n",
    "AllErrors = pd.DataFrame(cars, columns = ['Model', 'LES model 1', 'LES model 2', 'LES model 3'])\n",
    "print(AllErrors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4a3ba",
   "metadata": {},
   "source": [
    "# Méthode de Holt-Winter avec saisonnalité additive\n",
    "\n",
    "Les équations sont :\n",
    "\n",
    "$$L_t = \\alpha(Y_t − S_{t−s} ) + (1 − \\alpha)(L_{t−1} + b_{t−1} )$$\n",
    "$$b_t = \\beta (L_t − L_{t−1} ) + (1 − \\beta )b_{t−1}$$\n",
    "$$S_t = \\gamma(Y_t − L_t ) + (1 − \\gamma)S_{t−s}$$\n",
    "$$F_{t+m} = L_t + b_t m + S_{t−s+m}$$\n",
    "\n",
    "où $s$ est le nombre de périodes dans un cycle. Les valeurs initiales de $L_s$ et $b_s$ peuvent être comme dans le cas multiplicatif. Les indices saisonniers initiaux peuvent être pris comme :\n",
    "\n",
    "$$S_k = Y_k − L_s , k = 1, 2, ..., s.$$\n",
    "\n",
    "De même, les paramètres $\\alpha$, $\\beta$ , $\\gamma$ doivent se situer dans l'intervalle [0, 1], et peuvent à nouveau être sélectionnés en minimisant MAE, MSE ou MAPE.\n",
    "\n",
    "Ci-dessous, les données de production de ciment sont chargées et analysées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b685b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "series = read_excel('CementProduction.xls', sheet_name='Data', header=0,\n",
    "              index_col=0, parse_dates=True)\n",
    "series.index.freq = 'MS'\n",
    "series  = series['Observations'].iloc[:]\n",
    "\n",
    "# ===================================\n",
    "# Méthode de Holt-Winter dans différents scénarios #\n",
    "# ===================================\n",
    "# ===================================\n",
    "# Modèle 1 : Méthode de Holt-Winter avec tendance et saisonnalité additives\n",
    "# Ici, alpha = 0.3, beta=0.5, gamma=0.7\n",
    "# ===================================\n",
    "\n",
    "fit1 = ExponentialSmoothing(series, seasonal_periods=12, trend='add', seasonal='add').fit(smoothing_level = 0.3, smoothing_trend=0.5,  smoothing_seasonal=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8d2d0",
   "metadata": {},
   "source": [
    "Suivant l'exemple précédent, complétez la cellule ci-dessous pour appliquer la méthode de Holt-Winter avec une tendance additive et une saisonnalité multiplicative. Vous pouvez consulter la <a href=\"https://www.statsmodels.org/dev/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html\">documentation</a> de `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513da86-193c-47e1-b652-e51f9eab703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Modèle 2 : Méthode de Holt-Winter avec tendance additive et saisonnalité multiplicative\n",
    "# Ici, alpha = 0.3, beta=0.5, gamma=0.7\n",
    "# ===================================\n",
    "fit2 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63c6b6",
   "metadata": {},
   "source": [
    "Ensuite, lisez et exécutez le code ci-dessous pour les autres cas, et pour tracer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da31563-c1e7-4088-9e6d-a60c87e1bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Modèle 3 : Méthode de Holt-Winter avec tendance et saisonnalité additives\n",
    "# Ici, les paramètres alpha, beta et gamma sont optimisés\n",
    "# ===================================\n",
    "fit3 = ExponentialSmoothing(series, seasonal_periods=12, trend='add', seasonal='add').fit()\n",
    "\n",
    "# ===================================\n",
    "# Modèle 4 : Méthode de Holt-Winter avec tendance additive et saisonnalité multiplicative\n",
    "# Ici, les paramètres alpha, beta, et gamma sont optimisés\n",
    "# ===================================\n",
    "fit4 = ExponentialSmoothing(series, seasonal_periods=12, trend='add', seasonal='mul').fit()\n",
    "\n",
    "fit2.fittedvalues.plot(color='blue')\n",
    "fit1.fittedvalues.plot(color='red')\n",
    "fit3.fittedvalues.plot(color='green')\n",
    "fit4.fittedvalues.plot(color='yellow')\n",
    "\n",
    "print(\"Forecasting Cement Production with Holt-Winters method\")\n",
    "#=====================================\n",
    "# Tracés de temps et de prévisions\n",
    "#=====================================\n",
    "#series.rename('Time plot of original series')\n",
    "series.plot(color='black',label = 'Time plot of original series', legend=True)\n",
    "fit1.forecast(12).rename('Model 1: HW-additive seasonality').plot(color='red', legend=True)\n",
    "fit2.forecast(12).rename('Model 2: HW-multiplicative seasonality').plot(color='blue', legend=True)\n",
    "fit3.forecast(12).rename('Model 3: Opt HW-additive seasonality').plot(color='green', legend=True)\n",
    "fit4.forecast(12).rename('Model 4: Opt HW-multiplicative seasonality').plot(color='yellow', legend=True)\n",
    "pyplot.xlabel('Dates')\n",
    "pyplot.ylabel('Values')\n",
    "pyplot.title('HW method-based forecasts for cement production')\n",
    "pyplot.show()\n",
    "\n",
    "#====================================\n",
    "# Évaluation des erreurs\n",
    "#====================================\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE1=mean_squared_error(fit1.fittedvalues, series)\n",
    "MSE2=mean_squared_error(fit2.fittedvalues, series)\n",
    "MSE3=mean_squared_error(fit3.fittedvalues, series)\n",
    "MSE4=mean_squared_error(fit4.fittedvalues, series)\n",
    "\n",
    "#=====================================\n",
    "# Impression des paramètres et des erreurs pour chaque scénario\n",
    "#=====================================\n",
    "results=pd.DataFrame(index=[r\"alpha\", r\"beta\", r\"gamma\", r\"l0\", \"b0\", \"MSE\"])\n",
    "params = ['smoothing_level', 'smoothing_trend', 'smoothing_seasonal', 'initial_level', 'initial_trend']\n",
    "results[\"HW model 1\"] = [fit1.params[p] for p in params] + [MSE1]\n",
    "results[\"HW model 2\"] = [fit2.params[p] for p in params] + [MSE2]\n",
    "results[\"HW model 3\"] = [fit3.params[p] for p in params] + [MSE3]\n",
    "results[\"HW model 4\"] = [fit4.params[p] for p in params] + [MSE4]\n",
    "print(results)\n",
    "\n",
    "#=====================================\n",
    "# Évaluation et tracé des séries résiduelles pour chaque scénario\n",
    "#=====================================\n",
    "residuals1= fit1.fittedvalues - series\n",
    "residuals2= fit2.fittedvalues - series\n",
    "residuals3= fit3.fittedvalues - series\n",
    "residuals4= fit4.fittedvalues - series\n",
    "residuals1.plot(color='red', label=\"residual plot for model 1'\", legend=True)\n",
    "residuals2.plot(color='blue', label='residual plot for model 2', legend=True)\n",
    "residuals3.plot(color='green', label='residual plot for model 3', legend=True)\n",
    "residuals4.plot(color='yellow', label='residual plot for model 4', legend=True)\n",
    "\n",
    "pyplot.title('Residual plots for models 1-4')\n",
    "pyplot.show()\n",
    "\n",
    "#=====================================\n",
    "# Tracés ACF des séries résiduelles pour chaque scénario\n",
    "#=====================================\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(residuals1, title='Residual ACF for model 1', lags=50)\n",
    "plot_acf(residuals2, title='Residual ACF for model 2', lags=50)\n",
    "plot_acf(residuals3, title='Residual ACF for model 3', lags=50)\n",
    "plot_acf(residuals4, title='Residual ACF for model 4', lags=50)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
